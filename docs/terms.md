# Terms

| Term                 | Description                                                                                                                    |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| Context Length       | LLM 이 한 번에 처리할 수 있는 최대 token 수                                                                                    |
| Context Window       | model 이 한 번에 처리할 수 있는 최대 입출력 token 수                                                                           |
| max_tokens           | model 이 답변으로 생성할 수 있는 최대 token 수                                                                                 |
| Fine-tuning          |                                                                                                                                |
| Hallucinations(환각) | 시스템에서 Hallucination은 AI가 검색된 문서나 지식베이스의 실제 내용과 일치하지 않는 잘못된 정보를 생성하는 현상을 의미합니다. |
